{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.regular-expressions.info/catastrophic.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processando textos reais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos trabalhar com um conjunto de textos obtidos da Wikipedia em portugues (https://dumps.wikimedia.org/ptwiki/20210301/). O conjunto original de dados é bem grande (1.8 GB compactado), então eu criei um arquivo reduzido da seguinte forma:\n",
    "\n",
    "- Li os registros em formato XML (é assim que estão armazenados no *dump*)\n",
    "\n",
    "- Removi todos os registros que não diziam respeito a um artigo, mas que eram referentes a redirecionamento de pagina e outras meta-informações.\n",
    "\n",
    "- Removi todos os campos de cada registro exceto titulo e corpo.\n",
    "\n",
    "- Selecionei apenas $1\\%$ dos registros restantes.\n",
    "\n",
    "- Gravei cada registro como uma linha de texto no formato JSON em um arquivo dump_small.jsonln (\"JSON lines\")\n",
    "\n",
    "Vamos ler esse arquivo e ver seu conteudo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Numero de documentos: 11225\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "with open('dump_small.jsonln', 'r') as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line))\n",
    "        \n",
    "print(f'Numero de documentos: {len(data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['title', 'body'])\n"
     ]
    }
   ],
   "source": [
    "print(data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Alexandre (nome)\n"
     ]
    }
   ],
   "source": [
    "print(data[0]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data[0]['body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Como vocês podem ver, o texto está cheio de caracteres de estruturação de documento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Atividade:** Consulte a documentação da Wikipedia para descobrir o que são as marcações `[[`, `]]`, `{{` e ```}}```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R:** \n",
    "https://en.wikipedia.org/wiki/Help:Wikitext\n",
    "\n",
    "\n",
    "- [[ ]] => link para outra página da Wikipédia (fazer um hiperlink)\n",
    "- {{ }} => são templates que substitui por rum html desejado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos explorar o corpus para minerar itens de interesse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercicio:** Faça uma função que retorna uma lista com todos os links html de um texto deste corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Regex obtida de https://www.geeksforgeeks.org/python-check-url-string/\n",
    "pattern = r\"\"\"\n",
    "    (?i)  # Ignore case.\n",
    "    \\b  # Inicio de palavra.\n",
    "    (?:\n",
    "        https?://\n",
    "    |\n",
    "        www\n",
    "        \\d{0,3}\n",
    "        [.]\n",
    "    |\n",
    "        [a-z0-9.\\-]+\n",
    "        [.]\n",
    "        [a-z]{2,4}\n",
    "        /\n",
    "    )\n",
    "    (?:\n",
    "        [^\\s()<>]+\n",
    "    |\n",
    "        \\(\n",
    "        (?:\n",
    "            [^\\s()<>]+\n",
    "        |\n",
    "            \\(\n",
    "            [^\\s()<>]+\n",
    "            \\)\n",
    "        )*\n",
    "        \\)\n",
    "    )+\n",
    "    (?:\n",
    "        \\(\n",
    "        (?:\n",
    "            [^\\s()<>]+\n",
    "        |\n",
    "            \\(\n",
    "            [^\\s()<>]+\n",
    "            \\)\n",
    "        )*\n",
    "        \\)\n",
    "    |\n",
    "        [^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]\n",
    "    )\n",
    "\"\"\"\n",
    "matcher = re.compile(pattern, re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "http://www.geocities.com/kurogr/linearb.pdf\n",
      "https://web.archive.org/web/20080627021042/http://www.geocities.com/kurogr/linearb.pdf\n",
      "http://www.cm-aveiro.pt\n",
      "www.cm-aveiro.pt\n",
      "http://ww3.aeje.pt/avcultur/avcultur/ArkivDtA/Vol02/Vol02p081.htm|autor=Francisco\n",
      "https://www.ine.pt/xportal/xmain?xpid=INE&xpgid=ine_unid_territorial&menuBOUI=13707095&contexto=ut&selTab=tab3|titulo=Statistics\n",
      "www.ine.pt|lingua=en\n",
      "https://www.ine.pt/xportal/xmain?xpid=INE&xpgid=ine_unid_territorial&menuBOUI=13707095&contexto=ut&selTab=tab3|titulo=Statistics\n",
      "www.ine.pt|lingua=en\n",
      "http://www.ine.pt/ngt_server/attachfileu.jsp?look_parentBoui=379490&att_display=n&att_download=y\n",
      "http://www.ine.pt/investigadores/Quadros/Q101.zip\n",
      "http://www.dgterritorio.pt/ficheiros/cadastro/caop/caop_download/caop_2013_0/areasfregmundistcaop2013_2\n",
      "https://dre.pt/application/dir/pdf1s/2013/01/01901/0000200147.pdf|titulo=Lei\n",
      "http://www.ordens.presidencia.pt/?idc=153\n",
      "https://www.academia.edu/15680102/The_fable_of_the_cod_and_the_promised_sea._About_Portuguese_traditions_of_bacalhau|titulo=The\n",
      "https://www.ine.pt/xportal/xmain?xpid=INE&xpgid=ine_publicacoes\n",
      "http://censos.ine.pt/xportal/xmain?xpid=CENSOS&xpgid=censos_quadros\n",
      "http://www.ipma.pt/bin/file.data/climate-normal/cn_71-00_AVEIRO.pdf\n",
      "http://mca.cm-aveiro.pt/rede-de-museus/museu-da-cidade/\n",
      "https://www.adn-agenciadenoticias.com/2014/11/futuro-dos-transportes-coletivos-do.html\n",
      "http://www.aeva.eu/\n",
      "http://www.efta.edu.pt/\n",
      "http://musaveiro.pt/\n",
      "http://www.acaveiro.pt\n",
      "http://www.anmp.pt/anmp/pro/mun1/gem101l0.php?cod_ent=M3800\n",
      "http://www.ordens.presidencia.pt/?idc=153\n",
      "http://www.cm-aveiro.pt/\n",
      "http://www.ethnologue.com/show_language.asp?code=epo|título=Esperanto|publicado=[[Ethnologue]]|língua=en|acessodata=22\n",
      "http://uea.org/info/pt/kio_estas_uea\n",
      "https://meta.wikimedia.org/wiki/List_of_Wikipedias#100_000.2B_articles|título=List\n",
      "http://esperanto.pt/cxapelo2.htm|autor=Ancxjo|título=“Morskode...”|publicado=Bubo|edição=28|língua=eo|acessodata=22\n",
      "https://web.archive.org/web/20120321055847/http://esperanto.pt/cxapelo2.htm|arquivodata=2012-03-21|urlmorta=yes\n",
      "http://akademio-de-esperanto.org/oficialaj_informoj/oficialaj_informoj_1_2006.html|título=Oficialaj\n",
      "https://web.archive.org/web/20061224030314/http://www.akademio-de-esperanto.org/oficialaj_informoj/oficialaj_informoj_1_2006.html|arquivodata=2006-12-24|urlmorta=yes\n",
      "http://www.kunlaboro.pro.br/download/o-desafio-das-linguas.pdf|título=O\n",
      "http://www.panix.com/~dwolff/docs/|título=Three\n",
      "http://www.midiaindependente.org/eo/blue/|título=Sendependa\n",
      "https://web.archive.org/web/20130715053247/http://midiaindependente.org/eo/blue/|arquivodata=2013-07-15|urlmorta=yes\n",
      "http://www.radio-vatikana-esperanto.org/\n",
      "http://www.espirito.org.br/portal/artigos/geae/o-esp-e-o-esperanto.html\n",
      "https://web.archive.org/web/20091216040313/http://www.espirito.org.br/portal/artigos/geae/o-esp-e-o-esperanto.html\n",
      "http://www.aleph.com.br/useic/depesp.htm\n",
      "https://web.archive.org/web/20090105211100/http://www.aleph.com.br/useic/depesp.htm\n",
      "http://www.febnet.org.br/site/estudos.php?SecPad=40&Sec=170\n",
      "http://www.febnet.org.br/site/estudos.php?SecPad=40&Sec=170\n",
      "http://www.math.uu.se/esperanto/207pardue.pdf#search=%22esperanto%20%2Breligion%22\n",
      "http://www.math.uu.se/esperanto/207pardue.pdf#search=%22esperanto%20%2Breligion%22\n",
      "http://www.correioespirita.org.br/index.php?option=com_content&task=view&id=34&Itemid=31\n",
      "http://www.correioespirita.org.br/index.php?option=com_content&task=view&id=34&Itemid=31\n",
      "http://www.bahai.de/bahaaeligo/angla/englisch.htm\n",
      "http://www.bahai.de/bahaaeligo/angla/englisch.htm\n",
      "http://www.webcom.com/~donh/efaq.html|título=Esperanto\n",
      "https://web.archive.org/web/20090202101831/http://192.220.96.203/efaq.html|arquivodata=2009-02-02|urlmorta=yes\n",
      "http://porneniu.wordpress.com/learn-esperanto/|título=Esperanto\n",
      "http://www.oomoto.or.jp/Esperanto/index-es.html|título=The\n",
      "http://home.att.net/~el_sxadaj/kbiblio.htm|título=La\n",
      "https://web.archive.org/web/20061222215537/http://home.att.net/~el_sxadaj/kbiblio.htm|arquivodata=2006-12-22|urlmorta=yes\n",
      "http://www.esperanto.com.br/conheca/opiniao/comunicacao-idioma-e-consciencia-planetaria/|título=Comunicação|publicado=Esperanto\n",
      "http://www.febnet.org.br/blog/geral/noticias/feb-e-oomoto-preparam-livro-em-japones/|título=FEB\n",
      "https://books.google.com/books?id=B0loOBA3ejIC&pg=PA172\n",
      "http://parmadili.skf.org.pl/elendili/esperanto.jpg\n",
      "http://www.elendilion.pl/2007/06/18/tolkien-i-esperanto/\n",
      "http://en.wikipedia.org/wiki/Night_on_the_Galactic_Railroad\n",
      "http://www.ikue.org/tit912_03.html\n",
      "http://www.2-2.se/en/27.html\n",
      "https://web.archive.org/web/20080204081729/http://www.2-2.se/en/27.html\n",
      "http://www.esperanto.net\n",
      "http://esperantomondo.net/\n",
      "http://www.uea.org/info/portugale/ghisdate-pt.html\n",
      "http://www.uea.org\n",
      "http://www.esperanto.org.br\n",
      "http://www.esperanto.pt\n",
      "http://www.facebook.com.br/esperantomatogrosso\n",
      "http://ilei.brazilo.org/p/\n",
      "http://esperantoalagoas.wordpress.com\n",
      "http://www.aeaesperanto.com/\n",
      "http://aerj.org.br\n",
      "http://www.esperanto.com.br/bahia\n",
      "http://esperantogoias.com.br/\n",
      "http://www.easp.org.br\n",
      "http://www.esperantocaucaia-cek.blogspot.com/\n",
      "http://www.kke.org.br\n",
      "http://sites.google.com/site/esperantomt/\n",
      "http://esperantoparana.wordpress.com\n",
      "http://esperanto-pe.org\n",
      "http://santaremesperantoasocio.zip.net/\n",
      "http://www.soems.com.br/\n",
      "http://taguatek.org.br\n",
      "http://esperanto.us/budhana.html\n",
      "http://www.budhano.com|3=Ĉina\n",
      "http://www.ikue.org\n",
      "http://www001.upp.so-net.ne.jp/jble/budhismo_esp.html\n",
      "http://keli.chez.com\n",
      "http://www.oomoto.or.jp/Esperanto/index-es.html|3=Oomoto\n",
      "https://www.kursosaluton.org\n",
      "http://www.lernu.net\n",
      "http://www.kurso.com.br\n",
      "http://miaamiko.brazilo.org\n",
      "http://www.majstro.com/Web/Majstro/dict.php?gebrTaal=epo&prec=1&bronTaal=epo&doelTaal=por\n",
      "http://purl.org/net/voko/revo/\n",
      "http://www.bertilow.com/pmeg/index.html\n",
      "http://LaEtaPrinco.org\n",
      "http://www.esperanto.org/AEK\n",
      "http://bemi.free.fr/eo.html\n",
      "http://bejo.esperanto.org.br\n",
      "https://web.archive.org/web/20150920101859/http://www.radioriodejaneiro.am.br/?page_id=364\n",
      "http://esperanto.brazilo.org\n",
      "http://radioboanova.com.br/programacao/expresso-esperanto/\n",
      "http://bona-espero.org/\n",
      "http://www.esperanto.org/internacia/skolta\n",
      "http://www.tejo.org/pt\n",
      "http://www.ikso.net/kantaro/doku.php\n",
      "https://en.wikiversity.org/wiki/Primary_mathematics:Boolean_logic\n",
      "http://books.google.com.br/books?id=p0bpyag497oC&pg=PA102&dq=logical+conjunction+Definition&hl=pt-BR&sa=X&ei=WlN-UuOsDMnKkAf1xIC4Ag&ved=0CDYQ6AEwAQ#v=onepage&q=logical%20conjunction%20Definition&f=false\n",
      "http://books.google.com.br/books?id=EqizAAAAIAAJ&q=venn+diagram+logical+conjunction&dq=venn+diagram+logical+conjunction&hl=pt-BR&sa=X&ei=JFR-UoUhxJORB6W1gbAN&ved=0CEcQ6AEwAw\n",
      "http://www.encyclopediaofmath.org/index.php/Conjunction\n",
      "https://ia601502.us.archive.org/27/items/RegiesGeogrrficasBrasil2017/Regi%C3%B5es%20geogr%C3%A1ficas_Brasil%202017.pdf\n",
      "https://cidades.ibge.gov.br/brasil/sp/embu-das-artes/panorama\n",
      "geoftp.ibge.gov.br/Organizacao/Divisao_Territorial/2008/DTB_2008.zip\n",
      "http://www.pnud.org.br/arquivos/ranking-idhm-2010.pdf\n",
      "https://www.ibge.gov.br/estatisticas-novoportal/economicas/contas-nacionais/9088-produto-interno-bruto-dos-municipios.html?t=pib-por-municipio&c=3515004\n",
      "https://www.embudasartes.sp.gov.br/\n",
      "https://www.cmembu.sp.gov.br/\n",
      "http://www.al.sp.gov.br/repositorio/legislacao/lei.complementar/2011/lei.complementar-1139-16.06.2011.html|titulo=Lei\n",
      "https://www.pdui.sp.gov.br/rmsp/|titulo=Região\n",
      "http://archive.is/8EaLe|arquivodata=27\n",
      "http://www.cidadeshistoricas.art.br/embudasartes/emb_his_p.php\n",
      "http://www.cidadeshistoricas.art.br/embudasartes/emb_his_p.php\n",
      "http://www.embudigital.com.br/historia-de-embu/\n",
      "http://www.embudigital.com.br/historia-de-embu/\n",
      "http://g1.globo.com/Noticias/SaoPaulo/0,,MUL1351645-5605,00-CIDADE+DA+GRANDE+SP+TENTA+MUDAR+NOME+PARA+RESOLVER+CRISE+DE+IDENTIDADE.html\n",
      "http://www.embu.sp.gov.br/e-gov/noticia/index.php?ver=2463\n",
      "http://www1.folha.uol.com.br/cotidiano/909872-populacao-decide-que-embu-deve-se-tornar-embu-das-artes.shtml\n",
      "http://www.al.sp.gov.br/repositorio/legislacao/lei/2011/lei%20n.14.537,%20de%2006.09.2011.htm\n",
      "http://www.embu.sp.gov.br/Paginas/Cidade.php?Exibir=201\n",
      "http://pt.climate-data.org/location/10725/|título=Clima\n",
      "https://web.archive.org/web/20150405091812/http://pt.climate-data.org/location/10725/|arquivodata=2015-04-05|urlmorta=no\n",
      "http://g1.globo.com/sao-paulo/eleicoes/2016/noticia/2016/10/ney-santos-e-eleito-prefeito-de-embu-das-artes-sp.html\n",
      "http://www.embu.sp.gov.br/Paginas/Cidade.php?Exibir=206\n",
      "https://www.imprensaoficial.com.br/DO/BuscaDO2001Documento_11_4.aspx?link=/1973/ineditoriais/junho/20/pag_0009_2TIM6BGCRNUOSe8LEFA7U4SO2TJ.pdf&pagina=9&data=20/06/1973&caderno=Ineditoriais&paginaordenacao=100009|titulo=Relação\n",
      "http://telefonica.mediagroup.com.br/pt/Empresa/Nossa_Historia.aspx|título=Nossa\n",
      "http://g1.globo.com/economia/negocios/noticia/2012/04/telefonica-conclui-troca-da-marca-por-vivo.html|título=Telefônica\n",
      "http://www.embu.sp.gov.br/secretarias/turismo/atracoes/CapelaSaoLazaro.php\n",
      "https://web.archive.org/web/20081228091808/http://www.embu.sp.gov.br/secretarias/turismo/atracoes/CapelaSaoLazaro.php\n",
      "http://www.embu.sp.gov.br/secretarias/turismo/atracoes/MuseuArteSacra.php\n",
      "http://www.embu.sp.gov.br/secretarias/turismo/atracoes/ConjuntoSenhoraRosario.php\n",
      "http://www.embu.sp.gov.br/secretarias/turismo/atracoes/CentroHistorico.php\n",
      "http://www.embu.sp.gov.br/secretarias/turismo/atracoes/CentroCultural.php\n",
      "https://web.archive.org/web/20090126212925/http://embu.sp.gov.br/secretarias/turismo/atracoes/CentroCultural.php\n",
      "http://www.embu.sp.gov.br/Paginas/Cidade.php?Exibir=217\n",
      "http://www.cmembu.sp.gov.br/\n",
      "http://www.cmembu.sp.gov.br/|obra=www.cmembu.sp.gov.br|acessodata=2019-11-15\n",
      "http://www.tse.jus.br/imprensa/noticias-tse/2019/Outubro/4-de-outubro-falta-um-ano-para-as-eleicoes-municipais-de-2020|obra=www.tse.jus.br|acessodata=2019-11-15|lingua=pt-br\n",
      "http://www.embu.sp.gov.br\n",
      "http://www.embu.com.br\n",
      "http://WikiMapia.org/#lat=-23.654745&lon=-46.849308&z=13&l=9&m=h&v=2\n",
      "http://pt.trekearth.com/gallery/South_America/Brazil/Southeast/Sao_Paulo/Embu_das_Artes/\n",
      "http://www.mboy.com.br/index.php?tit=comochegar\n",
      "http://cvc.instituto-camoes.pt/dmdocuments/galegoportugues.pdf|título=A\n",
      "http://www.novomilenio.inf.br/idioma/20000900.htm|titulo=Novo\n",
      "www.novomilenio.inf.br\n",
      "http://www.novomilenio.inf.br/idioma/200009a.htm|titulo=Novo\n",
      "www.novomilenio.inf.br\n",
      "http://www.jstor.org/stable/3513048\n",
      "http://cantigas.fcsh.unl.pt/cantiga.asp?cdcant=1361&pv=sim|ano=2011|acessodata=30\n",
      "http://digitarq.arquivos.pt/details?id=4380613\n",
      "http://internacional.estadao.com.br/noticias/geral,professor-encontra-primeiro-texto-escrito-em-portugues,20020529p46797\n",
      "http://www.netprof.pt/pdf/revisao_TLEBS_2007.pdf\n",
      "http://www.publico.pt/n144785\n",
      "http://digitarq.arquivos.pt/details?id=1437285\n",
      "http://www.publico.pt/culturaipsilon/noticia/lingua-portuguesa-porque-27-de-junho-1659661|data=2014|acessodata=23\n",
      "http://digitarq.arquivos.pt/details?id=1461698\n",
      "https://www.academia.edu/2627222/A_cess%C3%A3o_do_mosteiro_de_Armeses_%C3%A0_condessa_Da_Sancha._Intersec%C3%A7%C3%B5es_escriturais_no_primeiro_documento_romance_da_Galiza|jornal=Revista\n",
      "http://consellodacultura.gal/mediateca/pubs.pdf/doc_en_galego.pdf\n",
      "https://www.academia.edu/10340715/Os_primeiros_escritos_em_galego-portugu%C3%AAs_revis%C3%A3o_e_balan%C3%A7o|jornal=Lingua\n",
      "http://www.uai.com.br/app/noticia/e-mais/2014/07/04/noticia-e-mais,156952/primeiro-documento-escrito-oficialmente-em-lingua-portuguesa-completa.shtml\n",
      "http://pt.wikipedia.org/w/index.php?title=Galaico-portugu%C3%AAs_%28controv%C3%A9rsia%29&action=history\n",
      "http://www.opatrimonio.org/en/documentos-culturacomun.asp\n",
      "http://www.opatrimonio.org/en/videos.asp\n",
      "http://cvc.instituto-camoes.pt/tempolingua/04.html\n",
      "https://cantigas.fcsh.unl.pt/index.asp\n",
      "http://www.novomilenio.inf.br/idioma/200009a.htm\n",
      "http://www.instituto-camoes.pt/cvc/tempolingua/07.html\n",
      "http://www.csarmento.uminho.pt/ndat_432.asp\n",
      "http://www.instituto-camoes.pt/cvc/bvc/revistalusitana/14/lusitana14_pag_251.pdf\n",
      "http://www.instituto-camoes.pt/CVC/hlp/geografia/mapa06.html\n",
      "http://www.ethnologue.com/show_family.asp?subid=92701\n",
      "http://www.scielo.br/scielo.php?pid=S0103-40141994000300069&script=sci_arttext\n",
      "http://tiooda.com.br/index.php/ciencia/cientistas/3284-franz-boas-o-antropologo-defendeu-a-igualdade-mental-entre-as-racas-humanas|obra=tiooda.com.br|acessodata=2019-09-06\n",
      "http://www.infoescola.com/portugues/linguistica/|título=\n",
      "http://brasilescola.uol.com.br/portugues/linguistica.htm|título=\n",
      "http://childes.psy.cmu.edu/#\n",
      "https://web.archive.org/web/20121211090005/http://childes.psy.cmu.edu/#\n",
      "http://cienciahoje.uol.com.br/revista-ch/revista-ch-2000/164/pdf_aberto/LINGUA.PDF\n",
      "https://web.archive.org/web/20140818191805/http://cienciahoje.uol.com.br/revista-ch/revista-ch-2000/164/pdf_aberto/LINGUA.PDF\n",
      "http://abralin.org\n",
      "https://web.archive.org/web/20070210031140/http://www.apl.org.pt/f_index.htm\n",
      "http://lingforum.com/forum\n",
      "http://appliedlinguistics.org\n",
      "http://francodousha.ipbfree.com\n",
      "http://www.ethnologue.com/14/iso639/codes.asp\n",
      "http://www.revel.inf.br/files/entrevistas/revel_14_entrevista_perini.pdf\n",
      "http://wais.stanford.edu/Brazil/brazil_orderandprogress42703.html\n",
      "wais.stanford.edu/|publicado=\n",
      "http://www.ebooksbrasil.org/eLibris/comte.html\n",
      "http://www.igrejapositivistabrasil.org.br\n",
      "http://www.scielo.br/scielo.php?pid=S0104-59701995000300006&script=sci_arttext\n",
      "http://proxy.furb.br/ojs/index.php/atosdepesquisa/article/view/3715\n",
      "http://proxy.furb.br/ojs/index.php/atosdepesquisa/article/view/3715\n"
     ]
    }
   ],
   "source": [
    "for item in data[:10]:\n",
    "    texto = item['body']\n",
    "    for match in matcher.findall(texto):\n",
    "        print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def links_html(data):\n",
    "    list_link = []\n",
    "    href = re.compile(r\"(?<=\\[\\[).*(?=\\]\\])\")  \n",
    "    matches = href.finditer(data)\n",
    "    for match in matches:\n",
    "        list_link.append(match.group())\n",
    "        \n",
    "    return list_link\n",
    "        \n",
    "# links_html(data[0][\"body\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercicio:** Faça uma função que recebe um texto do corpus e substitui todas as ocorrências de links da Wikipedia (textos entre os tags `[[` e `]]`) por texto simples, e retorna o documento limpo. Por exemplo, quando encontrar algo como `[[Etimologia|Etimologicamente]]` substituir por `Etimologicamente`. Você pode supor que os links não são *aninháveis*, como por exemplo `[[blablabla[[etc]]blebleble]]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lazy Vs greedy capture\n",
    "\n",
    "#greedy capture: pgear o maximo\n",
    "pattern = r\"\\[\\[(.*)\\]\\]\" # ? até a primeira captura\n",
    "# re.findall(pattern, texto)\n",
    "\n",
    "#lazy capture\n",
    "#localizar o que está entre barras\n",
    "pattern = r\"\\[\\[(.*?)\\]\\]\" # ? até a primeira captura\n",
    "# re.findall(pattern, texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#queremos subtituir\n",
    "# 14.32 pm\n",
    "def limpa_wikilinks(text):\n",
    "    pattern = r\"\\[\\[(?:[^|]*?\\|)*?([^|]*?)\\]\\]\"\n",
    "    repl = r'\\1'\n",
    "    matcher = re.compile(pattern)\n",
    "    return matcher.sub(repl, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa_aspas(texto):\n",
    "    pattern = r\"\"\"(['\"]+)(.*?)\\1\"\"\"\n",
    "    repl = r\"\\2\"\n",
    "    matcher = re.compile(pattern, re.VERBOSE)\n",
    "    return matcher.sub(repl, texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercicio**: Faça uma função que recebe um texto do corpus e remove todas as ocorrências de referências (textos entre os tags `<ref>` e `</ref>`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa_ref(texto):\n",
    "    pattern = r\"\"\"<ref.*?>.*?<\\/ref>\"\"\"\n",
    "    repl = r\"\"\n",
    "    matcher = re.compile(pattern, re.VERBOSE)\n",
    "    return matcher.sub(repl, texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa_url(texto):\n",
    "    # Regex obtida de https://www.geeksforgeeks.org/python-check-url-string/\n",
    "    pattern = r\"\"\"\n",
    "        (?i)  # Ignore case.\n",
    "        \\b  # Inicio de palavra.\n",
    "        (?:\n",
    "            https?://\n",
    "        |\n",
    "            www\n",
    "            \\d{0,3}\n",
    "            [.]\n",
    "        |\n",
    "            [a-z0-9.\\-]+\n",
    "            [.]\n",
    "            [a-z]{2,4}\n",
    "            /\n",
    "        )\n",
    "        (?:\n",
    "            [^\\s()<>]+\n",
    "        |\n",
    "            \\(\n",
    "            (?:\n",
    "                [^\\s()<>]+\n",
    "            |\n",
    "                \\(\n",
    "                [^\\s()<>]+\n",
    "                \\)\n",
    "            )*\n",
    "            \\)\n",
    "        )+\n",
    "        (?:\n",
    "            \\(\n",
    "            (?:\n",
    "                [^\\s()<>]+\n",
    "            |\n",
    "                \\(\n",
    "                [^\\s()<>]+\n",
    "                \\)\n",
    "            )*\n",
    "            \\)\n",
    "        |\n",
    "            [^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]\n",
    "        )\n",
    "    \"\"\"\n",
    "    repl = ''\n",
    "    matcher = re.compile(pattern, re.VERBOSE)\n",
    "    return matcher.sub(repl, texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercicio:** Faça uma função que recebe um texto do corpus e remove todos os templates (textos entre os tags `{{` e `}}`). Este exercício é desafiante: *os templates podem ser aninhados*! E agora, como proceder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa_templates(texto):\n",
    "    conta = 0\n",
    "    spans_proibidos = []\n",
    "    for item in re.finditer(r'{{|}}', texto):\n",
    "        if item[0] == '{{':\n",
    "            if conta == 0:\n",
    "                inicio = item.span()[0]\n",
    "            conta += 1\n",
    "        else:\n",
    "            conta -= 1\n",
    "            if conta == 0:\n",
    "                fim = item.span()[1]\n",
    "                spans_proibidos.append((inicio, fim))\n",
    "    texto_limpo = ''\n",
    "    inicio = 0\n",
    "    for span in spans_proibidos:\n",
    "        fim, novo_inicio = span\n",
    "        texto_limpo += texto[inicio:fim]\n",
    "        inicio = novo_inicio\n",
    "    texto_limpo += texto[inicio:]\n",
    "    return texto_limpo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercicio:** Usando os codigos desenvolvidos acima, faça uma função que recebe um texto do corpus e retorna a sua versão limpa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa_texto(texto):\n",
    "    return limpa_url(limpa_templates(limpa_aspas(limpa_wikilinks(limpa_ref(texto)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercicio:** Limpe todos os documentos e explore os resultados para ver o que mais dá para limpar. Nosso objetivo é ter uma coletânea de textos limpos para poder criar um vocabulário da língua portuguesa!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa_titulo(text):\n",
    "    pattern = r\"(=+)(.*)\\1\"\n",
    "    repl = r'\\2'\n",
    "    matcher = re.compile(pattern)\n",
    "    return matcher.sub(repl, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa_parenteses(text):\n",
    "    pattern = r\"\\((.*?)(\\))\"\n",
    "    repl = r'\\1'\n",
    "    matcher = re.compile(pattern)\n",
    "    return matcher.sub(repl, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa_colchetes(text):\n",
    "    pattern = r\"\\[+(.*?)\\]+\"\n",
    "    repl = r'\\1'\n",
    "    matcher = re.compile(pattern)\n",
    "    return matcher.sub(repl, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa_asteriscos(text):\n",
    "    pattern = r\"\\*\"\n",
    "    repl = r\"\"\n",
    "    matcher = re.compile(pattern)\n",
    "    return matcher.sub(repl, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa_hashtag(text):\n",
    "    pattern = r\"\\#\"\n",
    "    repl = r\"\"\n",
    "    matcher = re.compile(pattern)\n",
    "    return matcher.sub(repl, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pergunta se isso tudo bem\n",
    "def limpa_pontuacoes(text):\n",
    "    pattern = r\"\\W\"\n",
    "    repl = r\" \" \n",
    "    matcher = re.compile(pattern)\n",
    "    return matcher.sub(repl, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = limpa_pontuacoes(data[0][\"body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa_datas(text):\n",
    "    pattern = r\"(=+)(.*)\\1\"\n",
    "    repl = r'\\2'\n",
    "    matcher = re.compile(pattern)\n",
    "    return matcher.sub(repl, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa_tudo2(text):\n",
    "    return limpa_pontuacoes(limpa_datas(limpa_hashtag(limpa_asteriscos(limpa_colchetes(limpa_parenteses(limpa_titulo(limpa_texto(text))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in data:\n",
    "#     texto = item['body']\n",
    "#     texto_limpo_for = limpa_tudo2(texto)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dump_small_clean.jsonln\", \"w\", encoding = 'utf8') as file:\n",
    "    for i in range(len(data)):\n",
    "        json.dump({\"body\": limpa_tudo2(data[i]['body']),\"title\": data[i]['title']}, file)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Numero de documentos: 11225\n"
     ]
    }
   ],
   "source": [
    "data_limpa = []\n",
    "with open('dump_small_clean.jsonln', 'r') as file:\n",
    "    for line in file:\n",
    "        data_limpa.append(json.loads(line))\n",
    "        \n",
    "print(f'Numero de documentos: {len(data_limpa)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}